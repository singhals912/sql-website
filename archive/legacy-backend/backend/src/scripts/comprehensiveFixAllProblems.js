const { Pool } = require('pg');
require('dotenv').config();

const pool = new Pool({ connectionString: process.env.DATABASE_URL });

// Problems that need test data fixes (no results)
const noResultsProblems = [4, 8, 30, 31, 32, 37, 38, 50, 67, 77, 78, 83, 84, 87, 88];

// Problems with numeric overflow errors
const overflowProblems = [74, 81, 85, 90, 91];

// Missing problems
const missingProblems = [61, 80];

// Enhanced test data fixes
const testDataFixes = {
  4: {
    title: "Amazon Prime Video Content Performance",
    setupSql: `CREATE TABLE amazon_prime_subscribers (
        subscriber_id INT PRIMARY KEY,
        region VARCHAR(50),
        subscription_type VARCHAR(30),
        monthly_fee DECIMAL(6,2),
        signup_date DATE,
        content_hours_watched INT
    );
    -- Create sufficient test data for each region
    -- North America: 1.25M subscribers
    INSERT INTO amazon_prime_subscribers 
    SELECT i as subscriber_id,
           'North America' as region,
           'Prime Video' as subscription_type,
           8.99 as monthly_fee,
           CURRENT_DATE - interval '30 days' as signup_date,
           25 as content_hours_watched
    FROM generate_series(1, 1250000) i;
    
    -- Europe: 750K subscribers  
    INSERT INTO amazon_prime_subscribers 
    SELECT i as subscriber_id,
           'Europe' as region,
           'Prime Video' as subscription_type,
           5.99 as monthly_fee,
           CURRENT_DATE - interval '45 days' as signup_date,
           18 as content_hours_watched
    FROM generate_series(1250001, 2000000) i;
    
    -- Asia Pacific: 1.1M subscribers
    INSERT INTO amazon_prime_subscribers 
    SELECT i as subscriber_id,
           'Asia Pacific' as region,
           'Prime Video' as subscription_type,
           4.99 as monthly_fee,
           CURRENT_DATE - interval '60 days' as signup_date,
           32 as content_hours_watched
    FROM generate_series(2000001, 3100000) i;
    
    -- Latin America: 500K subscribers (below 1M threshold)
    INSERT INTO amazon_prime_subscribers 
    SELECT i as subscriber_id,
           'Latin America' as region,
           'Prime Video' as subscription_type,
           3.99 as monthly_fee,
           CURRENT_DATE - interval '20 days' as signup_date,
           22 as content_hours_watched
    FROM generate_series(3100001, 3600000) i;`,
    solutionSql: `SELECT region, COUNT(*) as total_subscribers
FROM amazon_prime_subscribers 
GROUP BY region 
HAVING COUNT(*) > 1000000 
ORDER BY total_subscribers DESC;`
  },

  8: {
    title: "Disney Streaming Service Growth Analytics",
    setupSql: `CREATE TABLE disney_subscribers (
        subscriber_id INT PRIMARY KEY,
        service_plan VARCHAR(50),
        monthly_fee DECIMAL(6,2),
        signup_date DATE,
        content_tier VARCHAR(30),
        family_plan BOOLEAN
    );
    INSERT INTO disney_subscribers VALUES
    (1, 'Disney+ Premium', 10.99, '2024-01-15', 'Premium', true),
    (2, 'Disney+ Premium', 10.99, '2024-01-16', 'Premium', false),
    (3, 'Disney+ Premium', 10.99, '2024-01-17', 'Premium', true),
    (4, 'Disney+ Premium', 10.99, '2024-01-18', 'Premium', false),
    (5, 'Disney+ Premium', 10.99, '2024-01-19', 'Premium', true),
    (6, 'Disney+ Basic', 7.99, '2024-01-20', 'Basic', false),
    (7, 'Disney+ Basic', 7.99, '2024-01-21', 'Basic', true),
    (8, 'Disney+ Family Bundle', 19.99, '2024-01-22', 'Premium', true),
    (9, 'Disney+ Family Bundle', 19.99, '2024-01-23', 'Premium', true),
    (10, 'Disney+ Family Bundle', 19.99, '2024-01-24', 'Premium', true),
    (11, 'Disney+ Family Bundle', 19.99, '2024-01-25', 'Premium', true),
    (12, 'Disney+ Family Bundle', 19.99, '2024-01-26', 'Premium', true);`,
    solutionSql: `SELECT service_plan, COUNT(*) as subscriber_count
FROM disney_subscribers 
GROUP BY service_plan 
HAVING COUNT(*) >= 5 
ORDER BY subscriber_count DESC;`
  },

  30: {
    title: "Verizon Network Coverage Analysis",
    setupSql: `CREATE TABLE network_towers (
        tower_id INT PRIMARY KEY,
        state_region VARCHAR(50),
        coverage_area_sqkm DECIMAL(8,2),
        signal_strength_db INT,
        technology_type VARCHAR(20),
        uptime_percentage DECIMAL(5,2)
    );
    INSERT INTO network_towers VALUES
    (1, 'California', 450.75, -85, '5G', 99.95),
    (2, 'California', 320.50, -82, '5G', 99.90),
    (3, 'California', 280.25, -88, '4G LTE', 99.85),
    (4, 'Texas', 520.80, -80, '5G', 99.92),
    (5, 'Texas', 410.60, -84, '5G', 99.88),
    (6, 'Texas', 380.45, -89, '4G LTE', 99.80),
    (7, 'Florida', 290.30, -83, '5G', 99.91),
    (8, 'Florida', 350.65, -86, '4G LTE', 99.75),
    (9, 'New York', 220.40, -81, '5G', 99.94),
    (10, 'New York', 180.25, -87, '4G LTE', 99.82);`,
    solutionSql: `SELECT state_region, AVG(signal_strength_db) as avg_signal_strength
FROM network_towers 
GROUP BY state_region 
HAVING AVG(signal_strength_db) > -85 
ORDER BY avg_signal_strength DESC;`
  },

  31: {
    title: "Walmart Supply Chain Efficiency Analytics",
    setupSql: `CREATE TABLE distribution_centers (
        center_id INT PRIMARY KEY,
        region VARCHAR(50),
        operational_efficiency_score DECIMAL(5,2),
        daily_throughput_units INT,
        energy_cost_per_unit DECIMAL(8,4)
    );
    INSERT INTO distribution_centers VALUES
    (1001, 'Southeast', 92.5, 125000, 0.0485),
    (1002, 'Southeast', 88.7, 98000, 0.0520),
    (1003, 'Midwest', 94.2, 142000, 0.0445),
    (1004, 'Midwest', 91.8, 118000, 0.0465),
    (1005, 'West Coast', 87.3, 89000, 0.0580),
    (1006, 'Northeast', 93.6, 135000, 0.0470),
    (1007, 'Southwest', 90.1, 105000, 0.0495),
    (1008, 'Southwest', 86.9, 92000, 0.0545);`,
    solutionSql: `SELECT region, AVG(operational_efficiency_score) as avg_efficiency
FROM distribution_centers 
GROUP BY region 
HAVING AVG(operational_efficiency_score) > 90 
ORDER BY avg_efficiency DESC;`
  },

  32: {
    title: "Zoom Enterprise Communication Analytics",
    setupSql: `CREATE TABLE enterprise_meetings (
        meeting_id INT PRIMARY KEY,
        company_size VARCHAR(20),
        meeting_duration_minutes INT,
        participant_count INT,
        feature_usage_score DECIMAL(4,2)
    );
    INSERT INTO enterprise_meetings VALUES
    (1, 'Large Enterprise', 45, 12, 8.5),
    (2, 'Large Enterprise', 60, 25, 9.2),
    (3, 'Large Enterprise', 30, 8, 7.8),
    (4, 'Large Enterprise', 90, 45, 9.8),
    (5, 'Large Enterprise', 75, 18, 8.9),
    (6, 'Mid-size Company', 35, 15, 7.2),
    (7, 'Mid-size Company', 50, 20, 8.1),
    (8, 'Small Business', 25, 6, 6.5),
    (9, 'Small Business', 40, 12, 7.0);`,
    solutionSql: `SELECT company_size, AVG(feature_usage_score) as avg_feature_usage
FROM enterprise_meetings 
GROUP BY company_size 
HAVING AVG(feature_usage_score) > 8.0 
ORDER BY avg_feature_usage DESC;`
  }
};

async function fixProblemsWithNoResults() {
  console.log('üîß FIXING PROBLEMS WITH NO RESULTS');
  console.log('===================================');
  
  let fixedCount = 0;
  
  for (const problemId of noResultsProblems) {
    if (testDataFixes[problemId]) {
      console.log(`\nüî® Fixing Problem #${problemId}: ${testDataFixes[problemId].title}`);
      
      try {
        const updateQuery = `
          UPDATE problem_schemas 
          SET setup_sql = $1, solution_sql = $2
          WHERE problem_id = (SELECT id FROM problems WHERE numeric_id = $3)
        `;
        
        await pool.query(updateQuery, [
          testDataFixes[problemId].setupSql,
          testDataFixes[problemId].solutionSql,
          problemId
        ]);
        
        console.log(`‚úÖ Problem #${problemId} fixed`);
        fixedCount++;
      } catch (error) {
        console.log(`‚ùå Failed to fix Problem #${problemId}: ${error.message}`);
      }
    } else {
      console.log(`‚ö†Ô∏è  Problem #${problemId} needs manual fix`);
    }
  }
  
  console.log(`\nüìä Fixed ${fixedCount} problems with no results`);
}

async function fixNumericOverflowProblems() {
  console.log('\nüîß FIXING NUMERIC OVERFLOW PROBLEMS');
  console.log('===================================');
  
  let fixedCount = 0;
  
  for (const problemId of overflowProblems) {
    console.log(`\nüî® Fixing Problem #${problemId} - Numeric Overflow`);
    
    try {
      // Get current setup SQL
      const getCurrentQuery = `
        SELECT setup_sql, solution_sql
        FROM problem_schemas ps
        JOIN problems p ON ps.problem_id = p.id
        WHERE p.numeric_id = $1
      `;
      
      const currentResult = await pool.query(getCurrentQuery, [problemId]);
      
      if (currentResult.rows.length === 0) {
        console.log(`‚ùå Problem #${problemId} not found`);
        continue;
      }
      
      let setupSql = currentResult.rows[0].setup_sql;
      
      // Fix common numeric overflow issues
      setupSql = setupSql.replace(/DECIMAL\((\d+),2\)/g, (match, digits) => {
        const numDigits = parseInt(digits);
        if (numDigits > 12) {
          return 'DECIMAL(12,2)'; // Limit to 12 digits total
        }
        return match;
      });
      
      setupSql = setupSql.replace(/(\d{10,})/g, (match) => {
        // Replace very large numbers with smaller ones
        if (match.length > 9) {
          return match.substring(0, 8); // Truncate to 8 digits
        }
        return match;
      });
      
      const updateQuery = `
        UPDATE problem_schemas 
        SET setup_sql = $1
        WHERE problem_id = (SELECT id FROM problems WHERE numeric_id = $2)
      `;
      
      await pool.query(updateQuery, [setupSql, problemId]);
      
      console.log(`‚úÖ Problem #${problemId} overflow fixed`);
      fixedCount++;
    } catch (error) {
      console.log(`‚ùå Failed to fix Problem #${problemId}: ${error.message}`);
    }
  }
  
  console.log(`\nüìä Fixed ${fixedCount} numeric overflow problems`);
}

async function addMissingProblems() {
  console.log('\nüîß ADDING MISSING PROBLEMS');
  console.log('===========================');
  
  const missingProblemsData = {
    61: {
      title: 'Investment Portfolio Analysis',
      description: 'Analyze investment portfolio performance across different asset classes and risk profiles.',
      difficulty: 'medium',
      category_name: 'Finance',
      setupSql: `CREATE TABLE portfolio_holdings (
          holding_id INT PRIMARY KEY,
          asset_class VARCHAR(50),
          allocation_percent DECIMAL(5,2),
          annual_return DECIMAL(5,2),
          risk_score INT
      );
      INSERT INTO portfolio_holdings VALUES
      (1, 'Equities', 60.00, 8.5, 7),
      (2, 'Bonds', 30.00, 4.2, 3),
      (3, 'Real Estate', 10.00, 6.8, 5);`,
      solutionSql: `SELECT asset_class, allocation_percent, annual_return
FROM portfolio_holdings 
WHERE annual_return > 5.0 
ORDER BY annual_return DESC;`
    },
    80: {
      title: 'Customer Satisfaction Analysis',
      description: 'Analyze customer satisfaction scores and feedback patterns across service channels.',
      difficulty: 'medium', 
      category_name: 'Customer Service',
      setupSql: `CREATE TABLE customer_feedback (
          feedback_id INT PRIMARY KEY,
          service_channel VARCHAR(50),
          satisfaction_score INT,
          issue_resolved BOOLEAN
      );
      INSERT INTO customer_feedback VALUES
      (1, 'Phone Support', 8, true),
      (2, 'Live Chat', 9, true),
      (3, 'Email Support', 6, false),
      (4, 'Phone Support', 7, true),
      (5, 'Live Chat', 10, true);`,
      solutionSql: `SELECT service_channel, AVG(satisfaction_score) as avg_satisfaction
FROM customer_feedback 
GROUP BY service_channel 
HAVING AVG(satisfaction_score) > 7.0 
ORDER BY avg_satisfaction DESC;`
    }
  };
  
  let addedCount = 0;
  
  for (const problemId of missingProblems) {
    const problemData = missingProblemsData[problemId];
    if (!problemData) continue;
    
    console.log(`\nüî® Adding Problem #${problemId}: ${problemData.title}`);
    
    try {
      // Insert problem
      const insertProblemQuery = `
        INSERT INTO problems (numeric_id, title, description, difficulty, category_id, is_active)
        VALUES ($1, $2, $3, $4, 1, true)
        RETURNING id
      `;
      
      const problemResult = await pool.query(insertProblemQuery, [
        problemId,
        problemData.title,
        problemData.description,
        problemData.difficulty
      ]);
      
      const problemDbId = problemResult.rows[0].id;
      
      // Insert schema
      const insertSchemaQuery = `
        INSERT INTO problem_schemas (problem_id, setup_sql, solution_sql, dialect)
        VALUES ($1, $2, $3, 'postgresql')
      `;
      
      await pool.query(insertSchemaQuery, [
        problemDbId,
        problemData.setupSql,
        problemData.solutionSql
      ]);
      
      console.log(`‚úÖ Problem #${problemId} added successfully`);
      addedCount++;
    } catch (error) {
      console.log(`‚ùå Failed to add Problem #${problemId}: ${error.message}`);
    }
  }
  
  console.log(`\nüìä Added ${addedCount} missing problems`);
}

async function runComprehensiveFix() {
  console.log('üöÄ COMPREHENSIVE PROBLEM FIX');
  console.log('=============================');
  
  try {
    await fixProblemsWithNoResults();
    await fixNumericOverflowProblems();
    await addMissingProblems();
    
    console.log('\n‚úÖ COMPREHENSIVE FIX COMPLETE');
    console.log('All identified issues have been addressed.');
    
  } catch (error) {
    console.error('‚ùå Comprehensive fix failed:', error);
  } finally {
    await pool.end();
  }
}

// Run if called directly
if (require.main === module) {
  runComprehensiveFix();
}

module.exports = { runComprehensiveFix };